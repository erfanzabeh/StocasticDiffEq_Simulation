{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adc2380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b7c4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 0) Utilities\n",
    "# ----------------------------\n",
    "def _rng(seed):\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "def pad_to_pmax(a_time_p, p_max):\n",
    "    \"\"\"Pad [T, p_true] -> [T, p_max] with zeros.\"\"\"\n",
    "    T, p = a_time_p.shape\n",
    "    out = np.zeros((T, p_max), dtype=a_time_p.dtype)\n",
    "    out[:, :p] = a_time_p\n",
    "    return out\n",
    "\n",
    "def enforce_l1_stability(a_time, l1_cap=0.95, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Simple, robust stability-ish heuristic for AR:\n",
    "      scale coefficients at each time t so sum_k |a_k(t)| <= l1_cap\n",
    "    This is sufficient to prevent most explosions for benchmarking.\n",
    "    \"\"\"\n",
    "    l1 = np.sum(np.abs(a_time), axis=1, keepdims=True)\n",
    "    scale = np.minimum(1.0, l1_cap / (l1 + eps))\n",
    "    return a_time * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92bb8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1) Smooth coefficient schedules (Task 1)\n",
    "# Each returns a_time with shape [T, p_true]\n",
    "# ----------------------------\n",
    "\n",
    "def schedule_sinusoid(T, p, rng, freq_range=(1/8000, 1/2000), amp_range=(0.05, 0.25)):\n",
    "    t = np.arange(T)\n",
    "    freqs  = rng.uniform(freq_range[0], freq_range[1], size=p)\n",
    "    phases = rng.uniform(0, 2*np.pi, size=p)\n",
    "    amps   = rng.uniform(amp_range[0], amp_range[1], size=p)\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    for k in range(p):\n",
    "        a[:, k] = amps[k] * np.sin(2*np.pi*freqs[k]*t + phases[k])\n",
    "    return a\n",
    "\n",
    "def schedule_fourier(T, p, rng, M=3, base_freq_range=(1/9000, 1/2500), amp_scale=0.18):\n",
    "    t = np.arange(T)\n",
    "    base_f = rng.uniform(base_freq_range[0], base_freq_range[1], size=p)\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    for k in range(p):\n",
    "        # Random harmonic amplitudes decay with m\n",
    "        for m in range(1, M+1):\n",
    "            A = rng.normal(0, amp_scale/(m**1.2))\n",
    "            phi = rng.uniform(0, 2*np.pi)\n",
    "            a[:, k] += A * np.sin(2*np.pi*(m*base_f[k])*t + phi)\n",
    "    return a\n",
    "\n",
    "def schedule_quasiperiodic(T, p, rng, f1_range=(1/9000, 1/3000), f2_range=(1/7000, 1/2500), amp_range=(0.05, 0.18)):\n",
    "    t = np.arange(T)\n",
    "    f1 = rng.uniform(f1_range[0], f1_range[1], size=p)\n",
    "    f2 = rng.uniform(f2_range[0], f2_range[1], size=p)\n",
    "    A1 = rng.uniform(amp_range[0], amp_range[1], size=p)\n",
    "    A2 = rng.uniform(amp_range[0], amp_range[1], size=p)\n",
    "    ph1 = rng.uniform(0, 2*np.pi, size=p)\n",
    "    ph2 = rng.uniform(0, 2*np.pi, size=p)\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    for k in range(p):\n",
    "        a[:, k] = A1[k]*np.sin(2*np.pi*f1[k]*t + ph1[k]) + A2[k]*np.sin(2*np.pi*f2[k]*t + ph2[k])\n",
    "    return a\n",
    "\n",
    "def schedule_polynomial_drift(T, p, rng, degree=2, coef_scale=0.20):\n",
    "    # use normalized time in [-1, 1]\n",
    "    tn = np.linspace(-1, 1, T)\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    for k in range(p):\n",
    "        # small polynomial coefficients\n",
    "        betas = rng.normal(0, coef_scale, size=degree+1)\n",
    "        # a_k(t) = sum_d beta_d * tn^d\n",
    "        ak = np.zeros(T)\n",
    "        for d in range(degree+1):\n",
    "            ak += betas[d] * (tn**d)\n",
    "        a[:, k] = ak\n",
    "    return a\n",
    "\n",
    "def schedule_logistic_transition(T, p, rng, amp_range=(0.05, 0.25), tau_range=(300, 1500)):\n",
    "    t = np.arange(T)\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    for k in range(p):\n",
    "        alo = rng.uniform(-amp_range[1], amp_range[1])\n",
    "        ahi = rng.uniform(-amp_range[1], amp_range[1])\n",
    "        t0  = rng.integers(int(0.2*T), int(0.8*T))\n",
    "        tau = rng.uniform(tau_range[0], tau_range[1])\n",
    "        s = 1.0 / (1.0 + np.exp(-(t - t0)/tau))\n",
    "        a[:, k] = alo + (ahi - alo) * s\n",
    "    return a\n",
    "\n",
    "def schedule_multi_sigmoid(T, p, rng, J=3, amp_step=0.12, tau_range=(200, 1200)):\n",
    "    t = np.arange(T)\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    for k in range(p):\n",
    "        base = rng.uniform(-0.05, 0.05)\n",
    "        ak = base * np.ones(T)\n",
    "        # multiple smooth steps\n",
    "        t0s = np.sort(rng.integers(int(0.1*T), int(0.9*T), size=J))\n",
    "        for j in range(J):\n",
    "            delta = rng.normal(0, amp_step)\n",
    "            tau = rng.uniform(tau_range[0], tau_range[1])\n",
    "            s = 1.0 / (1.0 + np.exp(-(t - t0s[j])/tau))\n",
    "            ak += delta * s\n",
    "        a[:, k] = ak\n",
    "    return a\n",
    "\n",
    "def schedule_gaussian_bumps(T, p, rng, J=4, amp_range=(0.05, 0.22), width_range=(200, 1200)):\n",
    "    t = np.arange(T)\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    for k in range(p):\n",
    "        base = rng.uniform(-0.03, 0.03)\n",
    "        ak = base * np.ones(T)\n",
    "        for _ in range(J):\n",
    "            mu = rng.uniform(0.1*T, 0.9*T)\n",
    "            sig = rng.uniform(width_range[0], width_range[1])\n",
    "            c = rng.uniform(-amp_range[1], amp_range[1])\n",
    "            ak += c * np.exp(-0.5 * ((t - mu)/sig)**2)\n",
    "        a[:, k] = ak\n",
    "    return a\n",
    "\n",
    "def schedule_smooth_random(T, p, rng, smooth_sigma=250, amp=0.20):\n",
    "    \"\"\"\n",
    "    GP-like smooth random function per lag (via Gaussian smoothing in frequency domain).\n",
    "    Produces a very different, non-periodic but smooth class.\n",
    "    \"\"\"\n",
    "    a = np.zeros((T, p), dtype=np.float32)\n",
    "    # build Gaussian kernel in frequency domain for convolution\n",
    "    freqs = np.fft.rfftfreq(T)\n",
    "    # Gaussian smoothing kernel: exp(-2*pi^2*sigma^2*f^2)\n",
    "    H = np.exp(-2*(np.pi**2) * (smooth_sigma**2) * (freqs**2))\n",
    "    for k in range(p):\n",
    "        w = rng.normal(0, 1, size=T)\n",
    "        W = np.fft.rfft(w)\n",
    "        sm = np.fft.irfft(W * H, n=T)\n",
    "        sm = sm / (np.std(sm) + 1e-8)\n",
    "        a[:, k] = (amp * sm).astype(np.float32)\n",
    "    return a\n",
    "\n",
    "# Registry of families you can benchmark\n",
    "SCHEDULES = {\n",
    "    \"sinusoid\": schedule_sinusoid,\n",
    "    \"fourier\": schedule_fourier,\n",
    "    \"quasiperiodic\": schedule_quasiperiodic,\n",
    "    \"poly_drift\": schedule_polynomial_drift,\n",
    "    \"logistic\": schedule_logistic_transition,\n",
    "    \"multi_sigmoid\": schedule_multi_sigmoid,\n",
    "    \"gaussian_bumps\": schedule_gaussian_bumps,\n",
    "    \"smooth_random\": schedule_smooth_random,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e0c32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2) Generic TVAR simulator (Task 1 core)\n",
    "# ----------------------------\n",
    "def simulate_tvar(a_time, noise_std=0.3, seed=0, burn_in=0):\n",
    "    \"\"\"\n",
    "    Simulate a TVAR process:\n",
    "        x_t = a(t)^T [x_{t-1}, ..., x_{t-p}] + eps_t\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    a_time : array, shape [T, p]\n",
    "        Time-varying coefficients for each lag.\n",
    "        a_time[t] = [a1(t), ..., ap(t)].\n",
    "    noise_std : float\n",
    "        Std dev of Gaussian innovations eps_t.\n",
    "    seed : int\n",
    "        RNG seed.\n",
    "    burn_in : int\n",
    "        Number of initial simulated samples to discard.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : array, shape [T]\n",
    "        Simulated time series after discarding burn-in.\n",
    "    \"\"\"\n",
    "    rng = _rng(seed)\n",
    "    T, p = a_time.shape\n",
    "\n",
    "    # Simulate a longer series, then drop the first burn_in samples\n",
    "    T_full = T + int(burn_in)\n",
    "    x_full = np.zeros(T_full, dtype=np.float32)\n",
    "    eps = rng.normal(0.0, noise_std, size=T_full).astype(np.float32)\n",
    "\n",
    "    # Initialize first p values\n",
    "    x_full[:p] = eps[:p]\n",
    "\n",
    "    # Main loop: for t >= p, use the same a_time indexing once we pass burn-in\n",
    "    # We want the kept segment (after burn-in) to correspond to a_time[0..T-1].\n",
    "    for t in range(p, T_full):\n",
    "        # Map full-time index t -> coefficient index tau in [0, T-1]\n",
    "        tau = t - int(burn_in)\n",
    "        if tau < 0:\n",
    "            # During burn-in: hold coefficients at the first value (a_time[0])\n",
    "            a_t = a_time[0]\n",
    "        else:\n",
    "            a_t = a_time[tau]\n",
    "\n",
    "        lags = x_full[t-p:t][::-1]  # [x_{t-1},...,x_{t-p}]\n",
    "        x_full[t] = float(np.dot(a_t, lags) + eps[t])\n",
    "\n",
    "    # Drop burn-in\n",
    "    x = x_full[int(burn_in):]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dc922dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3) One-sample generator + dataset wrapper (Task 2 groundwork)\n",
    "# ----------------------------\n",
    "\n",
    "def generate_one_tvar_sample(\n",
    "    T=10_000,\n",
    "    p_max=6,\n",
    "    schedule_name=\"sinusoid\",\n",
    "    noise_std=0.3,\n",
    "    seed=0,\n",
    "    l1_cap=0.95\n",
    "):\n",
    "    rng = _rng(seed)\n",
    "    p_candidates = np.array([1, 2, 4, 6], dtype=int)\n",
    "    p_true = int(rng.choice(p_candidates))\n",
    "\n",
    "    # coefficient schedule for true p\n",
    "    a_tp = SCHEDULES[schedule_name](T=T, p=p_true, rng=rng)\n",
    "    a_tp = enforce_l1_stability(a_tp, l1_cap=l1_cap)\n",
    "\n",
    "    # simulate signal\n",
    "    x = simulate_tvar(a_tp, noise_std=noise_std, seed=seed+123)\n",
    "\n",
    "    # pad coeffs to p_max for consistent storage\n",
    "    a_t = pad_to_pmax(a_tp.astype(np.float32), p_max)\n",
    "\n",
    "    meta = {\n",
    "        \"T\": T,\n",
    "        \"p_max\": p_max,\n",
    "        \"p_true\": p_true,\n",
    "        \"schedule\": schedule_name,\n",
    "        \"noise_std\": float(noise_std),\n",
    "        \"seed\": int(seed),\n",
    "        \"l1_cap\": float(l1_cap),\n",
    "        \"p_candidates\": [1, 2, 4, 6],\n",
    "    }\n",
    "    return x, a_t, meta\n",
    "\n",
    "def generate_dataset(\n",
    "    n_per_class=10,\n",
    "    classes=None,\n",
    "    T=1000,\n",
    "    noise_range=(0.1, 0.6),\n",
    "    seed=0,\n",
    "    dtype=np.float32\n",
    "):\n",
    "    \n",
    "    p_max = 10\n",
    "\n",
    "    if classes is None:\n",
    "        classes = list(SCHEDULES.keys())\n",
    "\n",
    "    rng = _rng(seed)\n",
    "    N = n_per_class * len(classes)\n",
    "\n",
    "    X = np.zeros((N, T), dtype=dtype)\n",
    "    A = np.zeros((N, T, p_max), dtype=dtype)\n",
    "    p_true = np.zeros((N,), dtype=np.int32)\n",
    "    class_id = np.zeros((N,), dtype=np.int32)\n",
    "    noise_std = np.zeros((N,), dtype=dtype)\n",
    "\n",
    "    class_names = list(classes)\n",
    "\n",
    "    metas = []\n",
    "    idx = 0\n",
    "    for cid, cname in enumerate(class_names):\n",
    "        for _ in range(n_per_class):\n",
    "            s = int(rng.integers(0, 2**31 - 1))\n",
    "            ns = float(rng.uniform(noise_range[0], noise_range[1]))\n",
    "            x, a_t, meta = generate_one_tvar_sample(\n",
    "                T=T, p_max=p_max, schedule_name=cname, noise_std=ns, seed=s\n",
    "            )\n",
    "            X[idx] = x.astype(dtype)\n",
    "            A[idx] = a_t.astype(dtype)\n",
    "            p_true[idx] = meta[\"p_true\"]\n",
    "            class_id[idx] = cid\n",
    "            noise_std[idx] = ns\n",
    "            metas.append(meta)\n",
    "            idx += 1\n",
    "\n",
    "    dataset = {\n",
    "        \"X\": X,\n",
    "        \"A\": A,\n",
    "        \"p_true\": p_true,\n",
    "        \"class_id\": class_id,\n",
    "        \"class_names\": np.array(class_names),\n",
    "        \"noise_std\": noise_std,\n",
    "        \"meta\": metas,  # Python list of dicts; fine for notebook use\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "def save_dataset_npz(path, dataset):\n",
    "    # Save large arrays in npz; meta dicts as object array\n",
    "    np.savez_compressed(\n",
    "        path,\n",
    "        X=dataset[\"X\"],\n",
    "        A=dataset[\"A\"],\n",
    "        p_true=dataset[\"p_true\"],\n",
    "        class_id=dataset[\"class_id\"],\n",
    "        class_names=dataset[\"class_names\"],\n",
    "        noise_std=dataset[\"noise_std\"],\n",
    "        meta=np.array(dataset[\"meta\"], dtype=object),\n",
    "    )\n",
    "\n",
    "def load_dataset_npz(path):\n",
    "    d = np.load(path, allow_pickle=True)\n",
    "    return {\n",
    "        \"X\": d[\"X\"],\n",
    "        \"A\": d[\"A\"],\n",
    "        \"p_true\": d[\"p_true\"],\n",
    "        \"class_id\": d[\"class_id\"],\n",
    "        \"class_names\": d[\"class_names\"],\n",
    "        \"noise_std\": d[\"noise_std\"],\n",
    "        \"meta\": list(d[\"meta\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a499832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# T = 1000\n",
    "# p_max = 20\n",
    "\n",
    "# x, a_t, meta = generate_one_tvar_sample(\n",
    "#     T=T, p_max=p_max,\n",
    "#     schedule_name=\"poly_drift\",\n",
    "#     noise_std=0.3,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# print(meta)\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.subplot(2,1,1)\n",
    "# plt.plot(x, alpha=0.8)\n",
    "# plt.title(\"TVAR signal x[t]\")\n",
    "# plt.grid(True, alpha=0.3)\n",
    "\n",
    "# plt.subplot(2,1,2)\n",
    "# p_true = meta[\"p_true\"]\n",
    "# for k in range(p_true):\n",
    "#     plt.plot(a_t[:,k], label=f\"a{k+1}(t)\")\n",
    "# plt.title(\"True coefficients a_k(t) for k<=p_true\")\n",
    "# plt.legend(ncol=4, fontsize=8)\n",
    "# plt.grid(True, alpha=0.3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "143e3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (80, 10000) A: (80, 10000, 10)\n",
      "class_names: ['sinusoid' 'fourier' 'quasiperiodic' 'poly_drift' 'logistic'\n",
      " 'multi_sigmoid' 'gaussian_bumps' 'smooth_random']\n",
      "p_true distribution: (array([1, 2, 4, 6], dtype=int32), array([17, 19, 29, 15]))\n"
     ]
    }
   ],
   "source": [
    "# 8 families\n",
    "classes = list(SCHEDULES.keys())\n",
    "\n",
    "# small pilot: 10 per family => 80 samples total\n",
    "pilot = generate_dataset(\n",
    "    n_per_class=10,\n",
    "    classes=classes,\n",
    "    T=10_000,\n",
    "    noise_range=(0.2, 0.5),\n",
    "    seed=123,\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "print(\"X:\", pilot[\"X\"].shape, \"A:\", pilot[\"A\"].shape)\n",
    "print(\"class_names:\", pilot[\"class_names\"])\n",
    "print(\"p_true distribution:\", np.unique(pilot[\"p_true\"], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fce5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_npz(\"tvar_pilot_T10000.npz\", pilot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "armodeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
